import jieba
from collections import Counter
import re
import difflib

# === åŸºæœ¬è®¾ç½® ===
file_path = r"/Users/inairmoriaty/Desktop/moriaty/moriaty/è„‘ç¼ ç¬”è®°æœ¬/COD/å¯¼å‡º/tame7.txt"

# === AIç—•è¿¹æ¨¡å¼ ===
ai_english_pattern = re.compile(r"\s[A-Z][a-zA-Z]+\s")  # ç©ºæ ¼åŒ…è£¹è‹±æ–‡
weird_quantifiers = ["ä¸€æŠ¹", "ä¸€ç¼•", "ä¸€ä¸", "ä¸€é˜µ", "ä¸€å›¢"]
suspicious_targets = ["ç©ºæ°”", "æ²‰é»˜", "æˆ¿é—´", "è€³è¯­", "ç©ºé—´", "èº«å½±", "æƒ…ç»ª", "å…‰çº¿"]

# === è¯»å–æ–‡æœ¬ ===
with open(file_path, "r", encoding="utf-8") as file:
    text = file.read()

# ç»Ÿè®¡è‹±æ–‡åæ ¼å¼é”™è¯¯
english_name_matches = ai_english_pattern.findall(text)

# åˆ†è¯ä¸è¯é¢‘ç»Ÿè®¡
text_clean = re.sub(r"[^\u4e00-\u9fff]", "", text)
words = jieba.lcut(text_clean)
filtered = [w for w in words if len(w) > 1]

counter = Counter(filtered)

# === è¾“å‡º ===
print("\nğŸ§  Top 30 ä¸­æ–‡è¯é¢‘ï¼š\n")
for word, count in counter.most_common(30):
    print(f"{word:<10}: {count} æ¬¡")

# === è‹±æ–‡åå¼‚å¸¸æ ‡è®° ===
print("\nğŸ” ç–‘ä¼¼ AI è‹±æ–‡åæ ¼å¼å¼‚å¸¸ï¼ˆç©ºæ ¼åŒ…è£¹ï¼‰:")
for match in set(english_name_matches):
    print(f"å‡ºç°åœºæ™¯ï¼šã€{match.strip()}ã€ â†’ å‡ºç°æ¬¡æ•°ï¼š{text.count(match)}")

# === å¯ç–‘é‡è¯æ­é…æ£€æµ‹ ===
print("\nâš ï¸ å¯ç–‘é‡è¯æ­é…ï¼š")
for q in weird_quantifiers:
    for t in suspicious_targets:
        phrase = q + t
        if phrase in text:
            print(f"å‘½ä¸­ï¼šã€{phrase}ã€ â†’ å‡ºç°æ¬¡æ•°ï¼š{text.count(phrase)}")

            # ==== é‡å¤å¥å­æ£€æµ‹ ====
print("\nğŸŒ€ æ£€æµ‹å®Œå…¨é‡å¤çš„å¥å­ï¼ˆ6å­—ä»¥ä¸Šï¼‰:")

# 1. å°†æ–‡æœ¬æŒ‰å¥å­åˆ†å‰²ï¼ˆæŒ‰ä¸­æ–‡å¥å·ã€é—®å·ã€å¹å·ï¼‰
sentence_list = re.split(r"[ã€‚ï¼ï¼Ÿ]", text)
sentence_list = [s.strip() for s in sentence_list if len(s.strip()) >= 6]  # åªä¿ç•™6å­—ä»¥ä¸Šçš„å¥å­

# 2. ç»Ÿè®¡é‡å¤å¥å­
sentence_counter = Counter(sentence_list)

# 3. è¾“å‡ºå‡ºç°ä¸¤æ¬¡ä»¥ä¸Šçš„å¥å­
repeated_sentences = {sent: count for sent, count in sentence_counter.items() if count > 1}

if repeated_sentences:
    for sent, count in repeated_sentences.items():
        print(f"ğŸ”ã€{sent}ã€‘ â†’ å‡ºç°äº† {count} æ¬¡")
else:
    print("âœ”ï¸ æ²¡æœ‰å‘ç°å®Œå…¨é‡å¤çš„å¥å­")

# ==== é«˜ç›¸ä¼¼åº¦é‡å¤å¥æ£€æµ‹ ====
print("\nğŸ§© æ£€æµ‹ç›¸ä¼¼é‡å¤å¥å­ï¼ˆç›¸ä¼¼åº¦ > 90%ï¼‰:")
checked_pairs = set()
similar_pairs = []

for i in range(len(sentence_list)):
    for j in range(i + 1, len(sentence_list)):
        s1, s2 = sentence_list[i], sentence_list[j]
        pair_key = tuple(sorted([s1, s2]))
        if pair_key in checked_pairs:
            continue
        similarity = difflib.SequenceMatcher(None, s1, s2).ratio()
        if similarity > 0.9:
            similar_pairs.append((s1, s2, round(similarity * 100, 2)))
        checked_pairs.add(pair_key)

if similar_pairs:
    for s1, s2, score in similar_pairs:
        print(f"\nğŸ”¶ ç›¸ä¼¼åº¦ {score}%ï¼š\nâ‘  {s1}\nâ‘¡ {s2}")
else:
    print("âœ”ï¸ æ²¡æœ‰å‘ç°é«˜ç›¸ä¼¼åº¦é‡å¤å¥")
